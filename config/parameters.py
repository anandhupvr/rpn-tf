import math


class Config:
    def __init__(self):
        self.network = 'vgg16'
        self.anchor_box_scales = [128, 256, 512]
        self.anchor_box_ratios = [[1, 1], [1, 2], [2, 1]]
        self.vgg16_path = 'vgg_16_2016_08_28/vgg16.ckpt'
        self.anchor_scales = [8, 16, 32]
        self.image_width = 224
        self.image_height = 224



        self.verbose = True

        # Name of base network
        self.network = 'vgg'

        # Setting for data augmentation
        self.use_horizontal_flips = False
        self.use_vertical_flips = False
        self.rot_90 = False

        # Anchor box scales
    # Note that if im_size is smaller, anchor_box_scales should be scaled
    # Original anchor_box_scales in the paper is [128, 256, 512]
        self.anchor_box_scales = [64, 128, 256] 

        # Anchor box ratios
        self.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]

        # Size to resize the smallest side of the image
        # Original setting in paper is 600. Set to 300 in here to save training time
        self.im_size = 224

        # image channel-wise mean to subtract
        self.img_channel_mean = [103.939, 116.779, 123.68]
        self.img_scaling_factor = 1.0

        # number of ROIs at once
        self.num_rois = 4

        # stride at the RPN (this depends on the network configuration)
        self.rpn_stride = 16

        self.balanced_classes = False

        # scaling the stdev
        self.std_scaling = 4.0
        self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]

        # overlaps for RPN
        self.rpn_min_overlap = 0.3
        self.rpn_max_overlap = 0.7

        # overlaps for classifier ROIs
        self.classifier_min_overlap = 0.2
        self.classifier_max_overlap = 0.5

        # placeholder for the class mapping, automatically generated by the parser
        self.class_mapping = None

        self.model_path = None
        self.feature_shape = (64, 19)


        self.RPN_ANCHOR_HEIGHTS = None
        self.RPN_ANCHOR_WIDTHS = None
        self.RPN_ANCHOR_BASE_SIZE = 64
        self.RPN_ANCHOR_SCALES = [1, 2 ** 1, 2 ** 2]
        self.RPN_ANCHOR_RATIOS = [0.5, 1, 2]
        # RPN提议框非极大抑制阈值(训练时可以增加该值来增加提议框)
        self.RPN_NMS_THRESHOLD_TRAINING = 0.7
        self.RPN_NMS_THRESHOLD_INFERENCE = 0.7

        self.BACKBONE_STRIDE = 16
        self.RPN_TRAIN_ANCHORS_PER_IMAGE = 256

        self.RPN_ANCHOR_NUM = len(self.RPN_ANCHOR_HEIGHTS) if self.RPN_ANCHOR_HEIGHTS is not None \
                                else len(self.RPN_ANCHOR_SCALES) * len(self.RPN_ANCHOR_RATIOS)
                    